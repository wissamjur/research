from surprise import SVD, KNNWithMeans, NMF
from surprise import Dataset
from surprise import accuracy
from surprise import Reader
from surprise.model_selection import train_test_split
from surprise.model_selection import cross_validate
from collections import defaultdict
from datetime import datetime as dt
import pandas as pd
import numpy as np

## import from custom scripts
from helpers.dataset import get_config_data, load_ratings
from LocalImpact.custom_train_test_split import train_test_split
from LocalImpact.compute_preceision_recall import compute_prec_rec
##


dataset_path = get_config_data()['dataset']
raw_ratings_df = load_ratings(dataset_path)[['userId','movieId','rating','timestamp']].rename({'movieId': 'itemId'}, axis=1)
raw_ratings_df['date'] = raw_ratings_df['timestamp'].apply(lambda x: dt.fromtimestamp(x).date())

### testing with recommender algorithms
data = Dataset.load_from_df(
                raw_ratings_df[['userId','itemId','rating']],
                Reader(rating_scale=(1,5))
            )
# sample random trainset and testset (default call using Surprise library train_test_split_method)
# in this code, I will use a pre-saved testset that was generated by this method since we need a custom method (below script)
### trainset, testset = train_test_split(data, test_size=.15, shuffle=True)
### testset_df = pd.DataFrame(testset, columns=['userId','itemId','rating'])
trainset, testset = train_test_split(raw_ratings_df)

# load a recommender algorithm: SVD, NMF or KNNWithMeans algorithm
    # algo = SVD()
    # algo = NMF()
sim_options = {
    'name': 'pearson',
    'user_based': True
    }
algo = KNNWithMeans(sim_options=sim_options)

# train the algorithm on the trainset, and predict ratings for the testset
algo.fit(trainset)
predictions = algo.test(testset)

# compute MAE and RMSE
accuracy.fcp(predictions)
accuracy.mae(predictions)
accuracy.rmse(predictions)
# 5-fold cross validation (to avoid bias)
# cross_validate(algo, data, measures=['RMSE', 'MAE', 'FCP'], cv=5, verbose=True)

# comput Precision and Recall
# compute_prec_rec(trainset, testset, data, algo, predictions)
### end testing

####################
# calculate accuracy at the neighborhood level
# map the predictions to each user.
mae_at_user = dict()
user_est_true = defaultdict(list)
for uid, iid, true_r, est, _ in predictions:
    user_est_true[uid].append((iid, true_r, est))

for uid, user_ratings in user_est_true.items():
    # calculate the mae for every user
    mae = (sum(abs(est - true_r) for (_, true_r, est) in user_ratings)) / len(user_ratings)

    mae_at_user[uid] = mae

mae_at_user_df = pd.DataFrame.from_dict(mae_at_user, orient='index').reset_index().sort_values(by=['index'])
mae_at_user_df.to_csv('NaturalNoise/LocalImpact/output/local-eval-after.csv', index=False)
######################